# Seokhyun Yoon - Data Analyst Portfolio

## ğŸ‘‹ About Me

Hello, I'm Seokhyun Yoon â€” a Statistics graduate from Simon Fraser University with a strong foundation in data analysis, machine learning, and business intelligence tools.

Iâ€™ve developed hands-on projects applying predictive modeling, time series analysis, and classification algorithms to real-world problems such as rainfall forecasting, housing price prediction, and rocket landing success rates.

I work primarily with **Python, R, SQL, Power BI, Tableau**, and version control tools like Git. I enjoy simplifying complex data into actionable insights and visual stories that help people make better decisions.

This repository showcases selected projects reflecting my technical skill set and ability to turn raw data into practical outcomes.  
ğŸ“„ [View My Resume (PDF)]([Sean Resume.pdf](https://github.com/SeanYooon/Data-Analysis-Portfolio-/blob/600ea4aff841bf852fe868ec03f4e31772f46f97/Sean%20Resume.pdf))  
ğŸ”— [Visit My LinkedIn](https://www.linkedin.com/in/seokhyun-yoon-241a61104/)

Letâ€™s connect!

---

## ğŸ“ Table of Contents

- [About](#about)
- [Portfolio Projects](#portfolio-projects)
  - Python
    - [SpaceX Falcon 9 Landing Prediction](#spacex-falcon-9-landing-prediction)
  - R
    - [Housing Price Prediction](#housing-price-prediction)
    - [Police Complaints Prediction](#police-complaints-prediction)
    - [Rainfall Time Series Forecasting](#rainfall-time-series-forecasting)
- [Education](#education)
- [Certificates](#certificates)
- [Contact](#contacts)

---

## ğŸ“Š Portfolio Projects

Here are some projects I've completed, along with brief descriptions of the tools, goals, and results.

---

# ğŸš€ SpaceX Falcon 9 Landing Prediction â€“ Classification + Mapping

## ğŸ“Š Project Overview
Predicted the landing success of SpaceX Falcon 9 first-stage boosters using a classification model. Combined machine learning with geospatial visualizations and API-sourced launch data to explore how mission factors influence outcomes.

---

## ğŸ”§ Tools & Techniques
Python, Pandas, Scikit-learn, Folium, Plotly, SpaceX API  
Classification (Logistic Regression, SVM, Random Forest), Feature Engineering, API Integration

---

## ğŸ§  Key Steps
- Scraped and queried launch data via the SpaceX REST API  
- Cleaned and transformed features (e.g., payload mass, orbit, site ID)  
- Engineered new features like payload class and binary landing outcome  
- Built and compared classification models: Logistic Regression, SVM, Random Forest  
- Evaluated models using accuracy, precision, confusion matrix  
- Created an interactive landing site map using Folium

---

## âœ… Results
- **Best model:** Random Forest Classifier (Accuracy ~87%)  
- **Top predictive features:** Launch Site, Payload Mass, Orbit  
- Created an interactive dashboard to visualize outcomes by location

---

## ğŸ“Š Visuals

| Landing Outcome Map (Folium)                              | Feature Importance          |
|-------------------------------------------------------|--------------------------------------------|
|![Landing Map](images/spacex_map.jpg)  | ![Feature Importance](images/spacex_accuracy.jpg) |



---

## ğŸ“‚ Files
- [`SpaceX_Machine_Learning_Prediction.ipynb`](files/SpaceX_Machine_Learning_Prediction_Part_5.jupyterlite.ipynb) â€“ full Jupyter notebook  
- [`falcon9.pdf`](files/spacex-final.pdf) â€“ final PDF summary

---

# ğŸ  Housing Price Prediction â€“ Connecticut Home Sales (2019â€“2020)

## ğŸ“Š Project Overview
Predicted residential housing prices in Connecticut using a dataset of 995,000+ property sales. Built a regression model using XGBoost, with focus on data cleaning, feature engineering, and model tuning.

## ğŸ”§ Tools & Technologies
R, XGBoost, tidyverse, glmnet, ranger, LightGBM, data.table

## ğŸ§  Key Steps
- Cleaned and prepared ~1M records from 2019â€“2020
- Created new time-based and interaction features
- Handled missing values through median/monthly imputation
- Applied log transformation to reduce skew
- Tuned XGBoost with randomized search + early stopping

## ğŸ“ˆ Results
- **Validation RMSE:** 1.15  
- **Validation RÂ²:** 0.26  
- Top features: Assessed value, Town (Greenwich), interaction terms

## ğŸ“Š Visuals

| Actual vs Predicted                               | Feature Importance          |
|-------------------------------------------------------|--------------------------------------------|
|![Actual vs Predicted](images/housing-importance.png)   | ![Feature Importance](images/housing-log.png) |


## ğŸ“‚ Files
- [`Housing-price-prediction.Rmd`](/files/Housing-price-prediction.Rmd) â€“ full notebook
- [`testing_data.csv`](data/Xte.csv) â€“ Test feature set (for prediction)
- [`testing_data.csv`](data/Xtr.csv) â€“ Training feature set
- [`testing_data.csv`](data/Ytr.csv) â€“ Training labels (house prices)
- [`pred0.csv`](data/pred0.csv) â€“ Output predictions on `Xte`
- [`Rainfall_Report.pdf`](files/485_Project_Report_Official.pdf) - Rainfall Project Report


---

### ğŸš“ Police Complaints Prediction

**Code:**  
- [`Final_Version.R`](https://github.com/jasondang01/440module2-jason-tyler-sean/blob/main/Final_Version.R)

**Goal:** Predict which CPD officers would receive complaints in 2015â€“2016 using data from 2000â€“2014.

**Description:** Modeled officer misconduct likelihood based on salary, prior complaints, and service data. Explored fairness and ethical data analysis.

**Skills:** Data cleaning, feature engineering, classification, ROC analysis  
**Tech Stack:** R, ggplot2, dplyr, tidyr, randomForest, XGBoost, pROC

**Results:** Built accurate classifiers using Random Forest and XGBoost. Evaluated models with AUC and ROC metrics.

---

# ğŸŒ§ï¸ Rainfall Forecasting â€“ Time Series Analysis (Perth, Australia)

## ğŸ“Š Project Overview
Forecasted monthly rainfall totals in Perth using a SARIMA model trained on 106 months of historical weather data. Applied time series modeling techniques (Box-Jenkins methodology) to capture seasonality and make future projections.

---

## ğŸ”§ Tools & Techniques
- R, `forecast`, `tseries`, `ggplot2`
- SARIMA modeling
- Box-Jenkins methodology
- Residual diagnostics (ACF/PACF)
- Forecast validation against real data

---

## ğŸ§  Key Steps
- Loaded and cleaned 106 months of historical rainfall data
- Conducted stationarity tests and seasonality checks
- Ran a grid search over SARIMA configurations with AIC optimization
- Selected SARIMA(1,0,0)x(0,1,1)[12] based on lowest AIC
- Forecasted 14 future months (months 107â€“120)
- Validated predictions against real airport rainfall data
- Sourced rainfall data from the Australian Bureau of Meteorology (BOM) official dataset
- Compared SARIMA model against a dynamic regression benchmark with external covariates

---

## ğŸ“ˆ Results
- **Model used:** SARIMA(1,0,0)x(0,1,1)[12]
- **Forecasted range:** Months 107â€“120
- **RMSE:** 1.095  
- **MAE:** 0.863  
- **95% CI coverage:** Forecasts closely followed actual values

---

## ğŸ“Š Visuals
| Forecast Plot                                | Residual ACF          |
|-------------------------------------------------------|--------------------------------------------|
|![Forecast Plot](images/Rplot.png) | ![Residual ACF](images/rainfallacf.png) |


---

## ğŸ“‚ Files
- [`Rainfall.Rmd`](rainfall_forecasting.Rmd) â€“ full notebook
- [`IDCJAC0009_009021_1800_Data.csv`](data/rainfall.csv) â€“ historical rainfall data  
- [`images/rainfall_forecast.pdf`](images/rainfall_forecast.pdf) â€“ forecast plot  
- [`images/residual_acf.pdf`](images/residual_acf.pdf) â€“ residual autocorrelation chart
- [`Rainfall_Report.pdf`](files/485_Project_Report_Official.pdf) - Rainfall report 
---
## ğŸ“Š Customer Churn Analysis & Prediction Dashboard

This project simulates a full analytics pipeline to analyze customer churn behavior using OLAP-style exploration, predictive modeling with PyTorch, and an interactive Tableau dashboard.

---

### ğŸš€ Overview

This project aims to identify key drivers of customer churn in a telecom company and provide business-friendly insights using statistical analysis and machine learning. The project demonstrates:

- Data cleaning and warehouse-style dimensional modeling  
- OLAP exploration (churn rates by contract, internet service, tenure, etc.)  
- Predictive churn classification using a neural network (PyTorch)  
- Key KPIs and trends visualized using Tableau  

---

### ğŸ§° Tools Used

- **Python** (pandas, PyTorch, scikit-learn, SMOTE)  
- **Tableau Public** for dashboards  
- **GitHub** for version control and documentation  

---

### ğŸ” OLAP-Style Exploration Highlights

- **Churn Rate by Contract Type**  
  Compared churn rates across `Month-to-month`, `One year`, and `Two year` contracts.  
  â†’ Found that short-term (Month-to-month) customers churned the most.

- **Churn by Internet Service**  
  Analyzed churn by service type: `DSL`, `Fiber optic`, or `No internet`.  
  â†’ Fiber optic users had the highest churn rate.

- **Churn by Tenure Group**  
  Created tenure buckets: `0â€“12m`, `13â€“24m`, `25â€“48m`, `49â€“72m`.  
  â†’ Longer-tenure customers churned significantly less.

- **Monthly Charges Bucket Analysis**  
  Grouped customers into pricing tiers: `Low`, `Medium`, `High`.  
  â†’ Higher monthly charges correlated with higher churn.

---

### ğŸ¤– Predictive Modeling

The churn classification model was built in PyTorch and achieved:

- **Accuracy:** ~79%  
- **F1-score for churners:** ~0.58  
- Applied class imbalance handling using SMOTE and weighted loss

---

### ğŸ“ˆ Tableau Dashboard

The dashboard summarizes churn performance and customer segmentation using KPI cards and bar charts.

| KPI: Churn Rate | Churn by Internet Service |
|----------------|---------------------------|
| ![KPI Churn](images/telco5.png) | ![Internet Type](images/telco2.png) |

| Churn by Gender | Churn by Contract Type |
|------------------|------------------------|
| ![Gender](images/telco4.png) | ![Contract](images/telco4.png) |

---
### ğŸ“‚ Files  
- [`churn_analysis.ipynb`](files/Churn.ipynb) â€“ Notebook  
- [`cleaned_telco_churn.csv`](files/cleaned_telco_churn.csv) â€“ Dataset
- [`Original_churn_data.csv`](files/WA_Fn-UseC_-Telco-Customer-Churn (1).csv) â€“ Dataset 
- [`README.md`]([Customer-Churn-Analysis/README.md](https://github.com/SeanYooon/telco-churn-analysis)) â€“ Project details  
---

### ğŸ“š Data Source

- [Telco Customer Churn Dataset (IBM Sample)](https://www.kaggle.com/datasets/blastchar/telco-customer-churn)

---

### ğŸ”— View Project

GitHub Repo: [Customer Churn Dashboard](https://github.com/SeanYooon/telco-churn-analysis/blob/main/README.md)

---

## ğŸ“ Education

**Simon Fraser University** â€” Burnaby, BC  
Bachelor of Science in Statistics  
*May 2018 â€“ December 2023*

---

## ğŸ“œ Certificates

While real projects are the best proof of skills, Iâ€™ve also completed these certifications:

- [IBM Data Science Professional Certificate](https://www.coursera.org/account/accomplishments/specialization/XQD6FNV9Q5FB) (Dec 2023)
- [Deep Learning Specialization â€“ DeepLearning.AI](https://coursera.org/share/HROP8FKWDLCK) (Oct 2024)  
- [Tableau for Data Analytics â€“ LinkedIn Learning](https://www.linkedin.com/learning/certificates/814d91fd0c6ab19bb16c9d29fd23fb3a7915ad908637ed0b5ba19f5684ac1dc5) (Jan 2023)

---

## ğŸ“¬ Contact

- ğŸ“§ Email: [seokhyun.sean.yoon@gmail.com](mailto:seokhyun.sean.yoon@gmail.com)  
- ğŸ’¼ LinkedIn: [@Seokhyun_Yoon](https://www.linkedin.com/in/seokhyun-yoon-241a61104/)
